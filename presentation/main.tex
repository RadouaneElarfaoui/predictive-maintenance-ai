\documentclass{beamer}

\usetheme{Madrid}
\usecolortheme{default}
\useinnertheme{rounded} % Rounded blocks
\useoutertheme{shadow} % Shadow for depth
\setbeamercolor{block title}{bg=structure.fg, fg=white} % Contrast for block titles
\setbeamercolor{block body}{bg=structure.fg!10}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumerate}

% Customize headline to display sections horizontally
\setbeamertemplate{headline}
{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=\paperwidth,ht=2.5ex,dp=1.125ex]{section in head/foot}%
    \insertsectionnavigationhorizontal{\paperwidth}{}{}%
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Customize footer to show subtitle instead of author
\setbeamertemplate{footline}
{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortsubtitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertshorttitle
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
    \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
    \insertframenumber{} / \inserttotalframenumber\hspace*{2ex} 
  \end{beamercolorbox}}%
  \vskip0pt%
}

% Section frame template with blur effect
\setbeamertemplate{section page}
{
  \begin{centering}
    \begin{beamercolorbox}[sep=12pt,center,rounded=true,shadow=true]{section title}
      \usebeamerfont{section title}\insertsection\par
    \end{beamercolorbox}
  \end{centering}
}

% Add section frame at the beginning of each section
\AtBeginSection{
  \begin{frame}
    \sectionpage
  \end{frame}
}

% Enhanced section highlighting in navigation
\setbeamertemplate{section in head/foot shaded}[default][50]
\setbeamercolor{section in head/foot}{fg=structure.fg!50}
\setbeamercolor{section in head/foot shaded}{fg=structure.fg!20}

% Meta-data
\title[Maintenance Prédictive]{Application de l'IA en Mécanique : Maintenance Prédictive}
\subtitle[Projet AI en Mcanique]{Projet AI en Mcanique}
\author{ARKHIS M’HAMMED 
RADOUANE ELARFAOUI
FARID ELABISISI
AMYNE ED-DARIF
SABANE MOHAMMED
KHALID LOULIJET}
\institute[]{École Nationale des Sciences Appliquées \\
Département Génie Mécanique \\Université Sidi Ben Abdellah
\\-Fes-}
\date{\today}

\begin{document}

% Title Page
\begin{frame}
    \titlepage
\end{frame}

% Table of Contents
\begin{frame}{Plan de la présentation}
    \tableofcontents
\end{frame}

% Section 1: Introduction
\section{Introduction}
\begin{frame}{Introduction}
    \begin{itemize}
        \item \textbf{Contexte :} Convergence de l'ingénierie mécanique et de l'intelligence artificielle (Industrie 4.0).
        \item \textbf{Sujet :} Maintenance prédictive des machines industrielles.
        \item \textbf{Objectif :} Anticiper les pannes pour optimiser la production et réduire les coûts.
        \item \textbf{Approche :} Utilisation de réseaux de neurones artificiels (RNA) sous MATLAB.
    \end{itemize}
\end{frame}
\section{Contexte et Objectifs}
\begin{frame}{Problématique}
    Les approches traditionnelles de maintenance présentent des limites :
    \vspace{0.5cm}
    \begin{itemize}
        \item \textbf{Maintenance Corrective :} 
        \begin{itemize}
            \item Réactive (après la panne).
            \item Coûts d'arrêt imprévisibles et élevés.
        \end{itemize}
        \item \textbf{Maintenance Préventive :}
        \begin{itemize}
            \item Planifiée (intervalles fixes).
            \item Gaspillage potentiel (remplacement de pièces saines).
        \end{itemize}
    \end{itemize}
    \vspace{0.5cm}
    \textbf{Question :} Comment intervenir au \textit{bon moment} ?
\end{frame}

\begin{frame}{Objectif du Projet}
    Développer un système de \textbf{Maintenance Prédictive Intelligent}.
    \vspace{0.5cm}
    \begin{block}{Mission}
        Concevoir et entraîner un modèle de réseau de neurones capable de classifier l'état de la machine en temps réel :
        \begin{itemize}
            \item \textbf{0} : Fonctionnement Normal
            \item \textbf{1} : Panne Détectée
        \end{itemize}
    \end{block}
    \vspace{0.5cm}
    Basé sur les données de capteurs (température, vitesse, couple, etc.).
\end{frame}
% Section 2: Types d'Apprentissage
\section{Types d'Apprentissage}
\begin{frame}{Types d'Apprentissage}
    L'intelligence artificielle utilise différents paradigmes d'apprentissage :
    \vspace{0.5cm}
    \begin{block}{1. Apprentissage Supervisé}
        \begin{itemize}
            \item Données étiquetées (entrées + sorties connues).
            \item Objectif : Apprendre une fonction de mapping.
            \item Exemples : Classification, Régression.
        \end{itemize}
    \end{block}
    \vspace{0.3cm}
    \begin{block}{2. Apprentissage Non Supervisé}
        \begin{itemize}
            \item Données non étiquetées.
            \item Objectif : Découvrir des patterns cachés.
            \item Exemples : Clustering, Réduction de dimensionnalité.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Types d'Apprentissage (suite)}
    \begin{block}{3. Apprentissage par Renforcement}
        \begin{itemize}
            \item Agent interagit avec un environnement.
            \item Apprend par essais-erreurs avec récompenses/pénalités.
            \item Exemples : Jeux, Robotique, Contrôle optimal.
        \end{itemize}
    \end{block}
    \vspace{0.5cm}
    \begin{block}{4. Apprentissage Semi-Supervisé}
        \begin{itemize}
            \item Combinaison de données étiquetées et non étiquetées.
            \item Utile quand l'étiquetage est coûteux.
        \end{itemize}
    \end{block}
    \vspace{0.3cm}
    \begin{alertblock}{Notre Projet}
        Utilise l'\textbf{Apprentissage Supervisé} (classification binaire : Normal/Panne).
    \end{alertblock}
\end{frame}

% Section 3: Types d'Architectures Neuronales
\section{Types d'Architectures Neuronales}
\begin{frame}{Régression Linéaire}
    \textbf{Régression Linéaire :} Modèle le plus simple pour prédire une valeur continue.
    \vspace{0.3cm}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \begin{block}{Formulation}
                $$y = w_0 + w_1 x_1 + w_2 x_2 + \ldots + w_n x_n$$
                où $w_i$ sont les poids et $x_i$ les features.
            \end{block}
            \vspace{0.3cm}
            \begin{itemize}
                \item \textbf{Avantages :} Simple, interprétable, rapide.
                \item \textbf{Limites :} Hypothèse de linéarité, ne capture pas les relations complexes.
            \end{itemize}
            \vspace{2cm}
        \end{column}
        \begin{column}{0.5\textwidth}
            % PLACEHOLDER IMAGE: Régression Linéaire
            % PROMPT: Image montrant un graphique de régression linéaire avec:
            % - Nuage de points (scatter plot) de données
            % - Ligne droite de régression ajustée (fitted line)
            % - Axes X (variable indépendante) et Y (variable dépendante)
            % - Éventuellement des résidus ou erreurs visibles
            % - Style: Professionnel, clair, avec légendes
            \vspace{-2cm}
            \begin{figure}
                \centering
                 \includegraphics[width=0.95\textwidth]{../linear_regression.png}
                \caption{Visualisation de la régression linéaire}
            \end{figure}
            \vfill
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Réseaux de Neurones Artificiels (RNA)}
    \textbf{Perceptron Multicouche (MLP) :} Architecture de base des RNA.
    \vspace{0.3cm}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \textbf{Composants :}
            \begin{itemize}
                \item Couche d'entrée
                \item Couches cachées
                \item Couche de sortie
                \item Fonctions d'activation
            \end{itemize}
            \vspace{0.3cm}
            \textbf{Avantages :}
            \begin{itemize}
                \item Capture des relations non-linéaires
                \item Apprentissage automatique de features
                \item Puissance d'approximation universelle
            \end{itemize}
            \vspace{0.3cm}
            \begin{block}{Notre Architecture}
                \texttt{patternnet} avec 2 couches cachées (100 et 50 neurones).
            \end{block}
        \end{column}
        \begin{column}{0.5\textwidth}
            % PLACEHOLDER IMAGE: Architecture Réseau de Neurones
            % PROMPT: Diagramme d'architecture d'un réseau de neurones montrant:
            % - Couche d'entrée avec plusieurs neurones (cercles/nœuds)
            % - Une ou plusieurs couches cachées avec connexions
            % - Couche de sortie
            % - Flèches/connexions entre les neurones (représentant les poids)
            % - Labels clairs: "Input Layer", "Hidden Layer(s)", "Output Layer"
            % - Style: Professionnel, schéma clair, couleurs distinctes par couche
            \begin{figure}
                \centering
                \includegraphics[width=\textwidth]{../neural_network_architecture.png}
                \caption{Architecture d'un RNA}
            \end{figure}
            \vspace{2cm}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Autres Architectures Neuronales}
    \begin{block}{1. Réseaux de Neurones Convolutifs (CNN)}
        \begin{itemize}
            \item Spécialisés pour les images et données spatiales.
            \item Utilisent des filtres convolutifs.
            \item Exemples : Reconnaissance d'images, Vision par ordinateur.
        \end{itemize}
    \end{block}
    \vspace{0.3cm}
    \begin{block}{2. Réseaux de Neurones Récurrents (RNN/LSTM)}
        \begin{itemize}
            \item Conçus pour les séries temporelles.
            \item Mémoire des états précédents.
            \item Exemples : Prédiction de séquences, Analyse de signaux temporels.
        \end{itemize}
    \end{block}
    \vspace{0.3cm}
    \begin{block}{3. Deep Learning}
        \begin{itemize}
            \item Réseaux avec plusieurs couches profondes.
            \item Capacité d'apprentissage hiérarchique de représentations.
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Comparaison des Approches}
    \begin{table}
        \centering
        \footnotesize
        \begin{tabular}{lccc}
            \toprule
            \textbf{Modèle} & \textbf{Complexité} & \textbf{Interprétabilité} & \textbf{Performance} \\
            \midrule
            Régression Linéaire & Faible & Élevée & Limitée \\
            RNA (MLP) & Moyenne & Moyenne & Bonne \\
            CNN & Élevée & Faible & Excellente (images) \\
            LSTM & Élevée & Faible & Excellente (séries temporelles) \\
            \bottomrule
        \end{tabular}
        \caption{Comparaison des architectures pour la maintenance prédictive}
    \end{table}
    \vspace{0.3cm}
    \begin{alertblock}{Choix pour notre projet}
        RNA (MLP) : Bon compromis entre complexité et performance pour données tabulaires.
    \end{alertblock}
\end{frame}



% Section 3: Méthodologie
\section{Méthodologie}
\begin{frame}{Description des Données}
    Données : \texttt{machine failure.csv} (Conditions de fonctionnement d'une machine-outil).
    
    \textbf{Variables d'entrée (Features) :}
    \begin{itemize}
        \item \textbf{Type de produit} (L, M, H) : Qualité/Contraintes.
        \item \textbf{Température de l'air [K]} : Ambiance.
        \item \textbf{Température du processus [K]} : Pièce/Outil.
        \item \textbf{Vitesse de rotation [rpm]} : Broche.
        \item \textbf{Couple [Nm]} : Force de torsion.
        \item \textbf{Usure de l'outil [min]} : Temps d'utilisation cumulé.
    \end{itemize}
    
    \textbf{Variable Cible (Target) :}
    \begin{itemize}
        \item \textbf{Machine Failure} (0 ou 1).
    \end{itemize}
\end{frame}

\begin{frame}{Implémentation sous MATLAB}
    \textbf{Outils :} MATLAB + Neural Network Toolbox.
    
    \vspace{0.3cm}
    \textbf{Étapes clés :}
    \begin{enumerate}
        \item \textbf{Préparation :} Chargement CSV, conversion 'Type' (catégoriel $\to$ numérique), transposition (Features $\times$ Samples).
        \item \textbf{Architecture :} \texttt{patternnet} (Reconnaissance de formes).
        \begin{itemize}
            \item 2 couches cachées : 100 et 50 neurones.
        \end{itemize}
        \item \textbf{Entraînement :} 
        \begin{itemize}
            \item Répartition : 70\% Train, 15\% Val, 15\% Test.
            \item Algorithme : Scaled Conjugate Gradient (trainscg).
        \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{Architecture du Réseau}
    \begin{flushleft}
        \begin{figure}
            \centering
            \includegraphics[width=0.3\textwidth]{../rapport/src/NN_Training_Tool_Summary.jpg}
            \caption{l'architecture et de l'entraînement (MATLAB)}
        \end{figure}
    \end{flushleft}
\end{frame}

% Section 4: Résultats
\section{Résultats et Analyse}
\begin{frame}{Performance Globale}
    \begin{alertblock}{Résultats sur l'ensemble de Test}
        Le modèle atteint une précision (\textit{Accuracy}) de \textbf{97.5\%}.
    \end{alertblock}
    
    \vspace{0.5cm}
    Analyse par classe :
    \begin{itemize}
        \item \textbf{Classe 0 (Normal) :} Excellente détection.
        \begin{itemize}
            \item Précision : 98.0\%
            \item Rappel : 99.4\%
        \end{itemize}
        \item \textbf{Classe 1 (Panne) :} Plus complexe (déséquilibre des classes).
        \begin{itemize}
            \item Précision : 69.2\%
            \item Rappel : 38.3\%
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Matrices de Confusion}
    \begin{figure}
        \centering
        \includegraphics[height=0.75\textheight]{../rapport/src/Overall_Confusion_Matrices.jpg}
        \caption{Matrices de confusion (Train, Val, Test, All)}
    \end{figure}
\end{frame}

\begin{frame}{Courbes ROC}
    La courbe ROC montre la capacité de discrimination du modèle.
    \begin{figure}
        \centering
        \includegraphics[height=0.65\textheight]{../rapport/src/ROC_Curves_Plot.jpg}
        \caption{Courbes ROC : Proches du coin supérieur gauche (Excellente performance).}
    \end{figure}
\end{frame}

\begin{frame}{Validation et Erreur}
    \begin{columns}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \centering
                \includegraphics[width=\textwidth]{../rapport/src/MSE_Performance_Plot.jpg}
                \caption{Performance (Cross-Entropy)}
            \end{figure}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{figure}
                \centering
                \includegraphics[width=\textwidth]{../rapport/src/Error_Histogram_Plot.jpg}
                \caption{Histogramme des erreurs}
            \end{figure}
        \end{column}
    \end{columns}
    \vspace{0.2cm}
    \footnotesize Pas de sur-apprentissage majeur (arrêt précoce à l'époque 37).
\end{frame}

% Section 5: Conclusion
\section{Conclusion}
\begin{frame}{Conclusion}
    \begin{itemize}
        \item \textbf{Réussite technique :} Mise en place d'un réseau de neurones performant (97.5\% de précision globale) avec MATLAB.
        \item \textbf{Maintenance Prédictive :} Preuve de concept validée pour l'anticipation des pannes à partir de données capteurs.
        \item \textbf{Perspectives :}
        \begin{itemize}
            \item Améliorer le rappel sur la classe "Panne" (gestion du déséquilibre des données).
            \item Tester d'autres architectures (Deep Learning, LSTM pour les séries temporelles).
            \item Déploiement sur un système temps réel.
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \centering
    \Huge \textbf{Merci de votre attention}
    
    \vspace{1cm}
    \Large Avez-vous des questions ?
\end{frame}

\end{document}
